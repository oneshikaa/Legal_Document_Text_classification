{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:54:57.887850: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-02 16:55:00.618778: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-02 16:55:01.186540: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-02 16:55:01.186591: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-02 16:55:13.322913: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-02 16:55:13.323127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-02 16:55:13.323148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/somesh/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil \n",
    "\n",
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization # to create AdamW optimizer \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7428 files belonging to 5 classes.\n",
      "Using 5943 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:55:45.351925: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-06-02 16:55:45.351998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (somesh-Inspiron-3593): /proc/driver/nvidia/version does not exist\n",
      "2023-06-02 16:55:45.387502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7428 files belonging to 5 classes.\n",
      "Using 1485 files for validation.\n",
      "Found 2002 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'data/train',\n",
    "    label_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'data/train',\n",
    "    label_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'data/test',\n",
    "    label_mode='categorical',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['argument', 'facts', 'precedent', 'ratio', 'ruling']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'The courts have also taken the view that where the husband had demanded a specific sum from his father-in-law and upon not being given,harassed and tortured the wife and after some days she died,such cases would clearly fall within the definition of \"dowry\" under the Act\\tRatio of the decision', shape=(), dtype=string)\n",
      "tf.Tensor([0. 0. 0. 1. 0.], shape=(5,), dtype=float32)\n",
      "Review: b'The courts have also taken the view that where the husband had demanded a specific sum from his father-in-law and upon not being given,harassed and tortured the wife and after some days she died,such cases would clearly fall within the definition of \"dowry\" under the Act\\tRatio of the decision'\n",
      "Review: b'The aforesaid eye-witnesses were cross-examined at length but even after such lengthy cross-examination these eye-witnesses account could not be shaken\\tRatio of the decision'\n",
      "Review: b'His second contention was that reference was made to a number of documents in some of these questions and those documents were not made available to the respondents for answering those questions\\tArgument'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 17:10:34.176221: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    print(text_batch[0])\n",
    "    print(label_batch[0])\n",
    "    for i in range(3):\n",
    "        print(f'Review: {text_batch.numpy()[i]}')\n",
    "        # label = label_batch[i]\n",
    "        # print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(5, activation='softmax', name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.5714858  0.52043355 0.5231227  0.55397797 0.5795657 ]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "# metrics = tf.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    return (2*recall*precision)/(recall+precision)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "# precision = tf.keras.metrics.Precision(name='precision')\n",
    "# recall = tf.keras.metrics.Recall(name='recall')\n",
    "# f1 = tf.keras.metrics.Mean(name='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics= [ accuracy , precision , recall , f1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/5\n",
      "  1/186 [..............................] - ETA: 52:55 - loss: 1.7438 - categorical_accuracy: 0.2812 - precision: 0.2000 - recall: 0.0625 - f1: 0.0952"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining model with \u001b[39m\u001b[39m{\u001b[39;00mtfhub_handle_encoder\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m classifier_model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_ds,\n\u001b[1;32m      3\u001b[0m                                validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[1;32m      4\u001b[0m                                epochs\u001b[39m=\u001b[39;49mepochs)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
